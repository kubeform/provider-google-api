apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  creationTimestamp: null
  labels:
    app.kubernetes.io/name: google.kubeform.com
    app.kubernetes.io/part-of: kubeform.com
  name: jobs.bigquery.google.kubeform.com
spec:
  group: bigquery.google.kubeform.com
  names:
    kind: Job
    listKind: JobList
    plural: jobs
    singular: job
  scope: Namespaced
  versions:
  - additionalPrinterColumns:
    - jsonPath: .status.phase
      name: Phase
      type: string
    name: v1alpha1
    schema:
      openAPIV3Schema:
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            properties:
              backendRef:
                description: LocalObjectReference contains enough information to let
                  you locate the referenced object inside the same namespace.
                properties:
                  name:
                    description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
                      TODO: Add other useful fields. apiVersion, kind, uid?'
                    type: string
                type: object
              providerRef:
                description: LocalObjectReference contains enough information to let
                  you locate the referenced object inside the same namespace.
                properties:
                  name:
                    description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
                      TODO: Add other useful fields. apiVersion, kind, uid?'
                    type: string
                type: object
              resource:
                properties:
                  copy:
                    description: Copies a table.
                    properties:
                      createDisposition:
                        description: 'Specifies whether the job is allowed to create
                          new tables. The following values are supported: CREATE_IF_NEEDED:
                          If the table does not exist, BigQuery creates the table.
                          CREATE_NEVER: The table must already exist. If it does not,
                          a ''notFound'' error is returned in the job result. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion Default value: "CREATE_IF_NEEDED" Possible
                          values: ["CREATE_IF_NEEDED", "CREATE_NEVER"]'
                        type: string
                      destinationEncryptionConfiguration:
                        description: Custom encryption configuration (e.g., Cloud
                          KMS keys)
                        properties:
                          kmsKeyName:
                            description: Describes the Cloud KMS encryption key that
                              will be used to protect destination BigQuery table.
                              The BigQuery Service Account associated with your project
                              requires access to this encryption key.
                            type: string
                        required:
                        - kmsKeyName
                        type: object
                      destinationTable:
                        description: The destination table.
                        properties:
                          datasetID:
                            description: The ID of the dataset containing this table.
                            type: string
                          projectID:
                            description: The ID of the project containing this table.
                            type: string
                          tableID:
                            description: The table. Can be specified '{{table_id}}'
                              if 'project_id' and 'dataset_id' are also set, or of
                              the form 'projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}'
                              if not.
                            type: string
                        required:
                        - tableID
                        type: object
                      sourceTables:
                        description: Source tables to copy.
                        items:
                          properties:
                            datasetID:
                              description: The ID of the dataset containing this table.
                              type: string
                            projectID:
                              description: The ID of the project containing this table.
                              type: string
                            tableID:
                              description: The table. Can be specified '{{table_id}}'
                                if 'project_id' and 'dataset_id' are also set, or
                                of the form 'projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}'
                                if not.
                              type: string
                          required:
                          - tableID
                          type: object
                        type: array
                      writeDisposition:
                        description: 'Specifies the action that occurs if the destination
                          table already exists. The following values are supported:
                          WRITE_TRUNCATE: If the table already exists, BigQuery overwrites
                          the table data and uses the schema from the query result.
                          WRITE_APPEND: If the table already exists, BigQuery appends
                          the data to the table. WRITE_EMPTY: If the table already
                          exists and contains data, a ''duplicate'' error is returned
                          in the job result. Each action is atomic and only occurs
                          if BigQuery is able to complete the job successfully. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion. Default value: "WRITE_EMPTY" Possible
                          values: ["WRITE_TRUNCATE", "WRITE_APPEND", "WRITE_EMPTY"]'
                        type: string
                    required:
                    - sourceTables
                    type: object
                  extract:
                    description: Configures an extract job.
                    properties:
                      compression:
                        description: The compression type to use for exported files.
                          Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
                          The default value is NONE. DEFLATE and SNAPPY are only supported
                          for Avro.
                        type: string
                      destinationFormat:
                        description: The exported file format. Possible values include
                          CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL
                          for models. The default value for tables is CSV. Tables
                          with nested or repeated fields cannot be exported as CSV.
                          The default value for models is SAVED_MODEL.
                        type: string
                      destinationUris:
                        description: A list of fully-qualified Google Cloud Storage
                          URIs where the extracted table should be written.
                        items:
                          type: string
                        type: array
                      fieldDelimiter:
                        description: When extracting data in CSV format, this defines
                          the delimiter to use between fields in the exported data.
                          Default is ','
                        type: string
                      printHeader:
                        description: Whether to print out a header row in the results.
                          Default is true.
                        type: boolean
                      sourceModel:
                        description: A reference to the model being exported.
                        properties:
                          datasetID:
                            description: The ID of the dataset containing this model.
                            type: string
                          modelID:
                            description: The ID of the model.
                            type: string
                          projectID:
                            description: The ID of the project containing this model.
                            type: string
                        required:
                        - datasetID
                        - modelID
                        - projectID
                        type: object
                      sourceTable:
                        description: A reference to the table being exported.
                        properties:
                          datasetID:
                            description: The ID of the dataset containing this table.
                            type: string
                          projectID:
                            description: The ID of the project containing this table.
                            type: string
                          tableID:
                            description: The table. Can be specified '{{table_id}}'
                              if 'project_id' and 'dataset_id' are also set, or of
                              the form 'projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}'
                              if not.
                            type: string
                        required:
                        - tableID
                        type: object
                      useAvroLogicalTypes:
                        description: Whether to use logical types when extracting
                          to AVRO format.
                        type: boolean
                    required:
                    - destinationUris
                    type: object
                  id:
                    type: string
                  jobID:
                    description: The ID of the job. The ID must contain only letters
                      (a-z, A-Z), numbers (0-9), underscores (_), or dashes (-). The
                      maximum length is 1,024 characters.
                    type: string
                  jobTimeoutMs:
                    description: Job timeout in milliseconds. If this time limit is
                      exceeded, BigQuery may attempt to terminate the job.
                    type: string
                  jobType:
                    description: The type of the job.
                    type: string
                  labels:
                    additionalProperties:
                      type: string
                    description: The labels associated with this job. You can use
                      these to organize and group your jobs.
                    type: object
                  load:
                    description: Configures a load job.
                    properties:
                      allowJaggedRows:
                        description: Accept rows that are missing trailing optional
                          columns. The missing values are treated as nulls. If false,
                          records with missing trailing columns are treated as bad
                          records, and if there are too many bad records, an invalid
                          error is returned in the job result. The default value is
                          false. Only applicable to CSV, ignored for other formats.
                        type: boolean
                      allowQuotedNewlines:
                        description: Indicates if BigQuery should allow quoted data
                          sections that contain newline characters in a CSV file.
                          The default value is false.
                        type: boolean
                      autodetect:
                        description: Indicates if we should automatically infer the
                          options and schema for CSV and JSON sources.
                        type: boolean
                      createDisposition:
                        description: 'Specifies whether the job is allowed to create
                          new tables. The following values are supported: CREATE_IF_NEEDED:
                          If the table does not exist, BigQuery creates the table.
                          CREATE_NEVER: The table must already exist. If it does not,
                          a ''notFound'' error is returned in the job result. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion Default value: "CREATE_IF_NEEDED" Possible
                          values: ["CREATE_IF_NEEDED", "CREATE_NEVER"]'
                        type: string
                      destinationEncryptionConfiguration:
                        description: Custom encryption configuration (e.g., Cloud
                          KMS keys)
                        properties:
                          kmsKeyName:
                            description: Describes the Cloud KMS encryption key that
                              will be used to protect destination BigQuery table.
                              The BigQuery Service Account associated with your project
                              requires access to this encryption key.
                            type: string
                        required:
                        - kmsKeyName
                        type: object
                      destinationTable:
                        description: The destination table to load the data into.
                        properties:
                          datasetID:
                            description: The ID of the dataset containing this table.
                            type: string
                          projectID:
                            description: The ID of the project containing this table.
                            type: string
                          tableID:
                            description: The table. Can be specified '{{table_id}}'
                              if 'project_id' and 'dataset_id' are also set, or of
                              the form 'projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}'
                              if not.
                            type: string
                        required:
                        - tableID
                        type: object
                      encoding:
                        description: The character encoding of the data. The supported
                          values are UTF-8 or ISO-8859-1. The default value is UTF-8.
                          BigQuery decodes the data after the raw, binary data has
                          been split using the values of the quote and fieldDelimiter
                          properties.
                        type: string
                      fieldDelimiter:
                        description: The separator for fields in a CSV file. The separator
                          can be any ISO-8859-1 single-byte character. To use a character
                          in the range 128-255, you must encode the character as UTF8.
                          BigQuery converts the string to ISO-8859-1 encoding, and
                          then uses the first byte of the encoded string to split
                          the data in its raw, binary state. BigQuery also supports
                          the escape sequence "\t" to specify a tab separator. The
                          default value is a comma (',').
                        type: string
                      ignoreUnknownValues:
                        description: 'Indicates if BigQuery should allow extra values
                          that are not represented in the table schema. If true, the
                          extra values are ignored. If false, records with extra columns
                          are treated as bad records, and if there are too many bad
                          records, an invalid error is returned in the job result.
                          The default value is false. The sourceFormat property determines
                          what BigQuery treats as an extra value: CSV: Trailing columns
                          JSON: Named values that don''t match any column names'
                        type: boolean
                      maxBadRecords:
                        description: The maximum number of bad records that BigQuery
                          can ignore when running the job. If the number of bad records
                          exceeds this value, an invalid error is returned in the
                          job result. The default value is 0, which requires that
                          all records are valid.
                        format: int64
                        type: integer
                      nullMarker:
                        description: Specifies a string that represents a null value
                          in a CSV file. For example, if you specify "\\N", BigQuery
                          interprets "\\N" as a null value when loading a CSV file.
                          The default value is the empty string. If you set this property
                          to a custom value, BigQuery throws an error if an empty
                          string is present for all data types except for STRING and
                          BYTE. For STRING and BYTE columns, BigQuery interprets the
                          empty string as an empty value.
                        type: string
                      projectionFields:
                        description: If sourceFormat is set to "DATASTORE_BACKUP",
                          indicates which entity properties to load into BigQuery
                          from a Cloud Datastore backup. Property names are case sensitive
                          and must be top-level properties. If no properties are specified,
                          BigQuery loads all properties. If any named property isn't
                          found in the Cloud Datastore backup, an invalid error is
                          returned in the job result.
                        items:
                          type: string
                        type: array
                      quote:
                        description: The value that is used to quote data sections
                          in a CSV file. BigQuery converts the string to ISO-8859-1
                          encoding, and then uses the first byte of the encoded string
                          to split the data in its raw, binary state. The default
                          value is a double-quote ('"'). If your data does not contain
                          quoted sections, set the property value to an empty string.
                          If your data contains quoted newline characters, you must
                          also set the allowQuotedNewlines property to true.
                        type: string
                      schemaUpdateOptions:
                        description: 'Allows the schema of the destination table to
                          be updated as a side effect of the load job if a schema
                          is autodetected or supplied in the job configuration. Schema
                          update options are supported in two cases: when writeDisposition
                          is WRITE_APPEND; when writeDisposition is WRITE_TRUNCATE
                          and the destination table is a partition of a table, specified
                          by partition decorators. For normal tables, WRITE_TRUNCATE
                          will always overwrite the schema. One or more of the following
                          values are specified: ALLOW_FIELD_ADDITION: allow adding
                          a nullable field to the schema. ALLOW_FIELD_RELAXATION:
                          allow relaxing a required field in the original schema to
                          nullable.'
                        items:
                          type: string
                        type: array
                      skipLeadingRows:
                        description: 'The number of rows at the top of a CSV file
                          that BigQuery will skip when loading the data. The default
                          value is 0. This property is useful if you have header rows
                          in the file that should be skipped. When autodetect is on,
                          the behavior is the following: skipLeadingRows unspecified
                          - Autodetect tries to detect headers in the first row. If
                          they are not detected, the row is read as data. Otherwise
                          data is read starting from the second row. skipLeadingRows
                          is 0 - Instructs autodetect that there are no headers and
                          data should be read starting from the first row. skipLeadingRows
                          = N > 0 - Autodetect skips N-1 rows and tries to detect
                          headers in row N. If headers are not detected, row N is
                          just skipped. Otherwise row N is used to extract column
                          names for the detected schema.'
                        format: int64
                        type: integer
                      sourceFormat:
                        description: The format of the data files. For CSV files,
                          specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
                          For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON".
                          For Avro, specify "AVRO". For parquet, specify "PARQUET".
                          For orc, specify "ORC". [Beta] For Bigtable, specify "BIGTABLE".
                          The default value is CSV.
                        type: string
                      sourceUris:
                        description: 'The fully-qualified URIs that point to your
                          data in Google Cloud. For Google Cloud Storage URIs: Each
                          URI can contain one ''*'' wildcard character and it must
                          come after the ''bucket'' name. Size limits related to load
                          jobs apply to external data sources. For Google Cloud Bigtable
                          URIs: Exactly one URI can be specified and it has be a fully
                          specified and valid HTTPS URL for a Google Cloud Bigtable
                          table. For Google Cloud Datastore backups: Exactly one URI
                          can be specified. Also, the ''*'' wildcard character is
                          not allowed.'
                        items:
                          type: string
                        type: array
                      timePartitioning:
                        description: Time-based partitioning specification for the
                          destination table.
                        properties:
                          expirationMs:
                            description: Number of milliseconds for which to keep
                              the storage for a partition. A wrapper is used here
                              because 0 is an invalid value.
                            type: string
                          field:
                            description: If not set, the table is partitioned by pseudo
                              column '_PARTITIONTIME'; if set, the table is partitioned
                              by this field. The field must be a top-level TIMESTAMP
                              or DATE field. Its mode must be NULLABLE or REQUIRED.
                              A wrapper is used here because an empty string is an
                              invalid value.
                            type: string
                          type:
                            description: The only type supported is DAY, which will
                              generate one partition per day. Providing an empty string
                              used to cause an error, but in OnePlatform the field
                              will be treated as unset.
                            type: string
                        required:
                        - type
                        type: object
                      writeDisposition:
                        description: 'Specifies the action that occurs if the destination
                          table already exists. The following values are supported:
                          WRITE_TRUNCATE: If the table already exists, BigQuery overwrites
                          the table data and uses the schema from the query result.
                          WRITE_APPEND: If the table already exists, BigQuery appends
                          the data to the table. WRITE_EMPTY: If the table already
                          exists and contains data, a ''duplicate'' error is returned
                          in the job result. Each action is atomic and only occurs
                          if BigQuery is able to complete the job successfully. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion. Default value: "WRITE_EMPTY" Possible
                          values: ["WRITE_TRUNCATE", "WRITE_APPEND", "WRITE_EMPTY"]'
                        type: string
                    required:
                    - destinationTable
                    - sourceUris
                    type: object
                  location:
                    description: The geographic location of the job. The default value
                      is US.
                    type: string
                  project:
                    type: string
                  query:
                    description: Configures a query job.
                    properties:
                      allowLargeResults:
                        description: If true and query uses legacy SQL dialect, allows
                          the query to produce arbitrarily large result tables at
                          a slight cost in performance. Requires destinationTable
                          to be set. For standard SQL queries, this flag is ignored
                          and large results are always allowed. However, you must
                          still set destinationTable when result size exceeds the
                          allowed maximum response size.
                        type: boolean
                      createDisposition:
                        description: 'Specifies whether the job is allowed to create
                          new tables. The following values are supported: CREATE_IF_NEEDED:
                          If the table does not exist, BigQuery creates the table.
                          CREATE_NEVER: The table must already exist. If it does not,
                          a ''notFound'' error is returned in the job result. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion Default value: "CREATE_IF_NEEDED" Possible
                          values: ["CREATE_IF_NEEDED", "CREATE_NEVER"]'
                        type: string
                      defaultDataset:
                        description: Specifies the default dataset to use for unqualified
                          table names in the query. Note that this does not alter
                          behavior of unqualified dataset names.
                        properties:
                          datasetID:
                            description: The dataset. Can be specified '{{dataset_id}}'
                              if 'project_id' is also set, or of the form 'projects/{{project}}/datasets/{{dataset_id}}'
                              if not.
                            type: string
                          projectID:
                            description: The ID of the project containing this table.
                            type: string
                        required:
                        - datasetID
                        type: object
                      destinationEncryptionConfiguration:
                        description: Custom encryption configuration (e.g., Cloud
                          KMS keys)
                        properties:
                          kmsKeyName:
                            description: Describes the Cloud KMS encryption key that
                              will be used to protect destination BigQuery table.
                              The BigQuery Service Account associated with your project
                              requires access to this encryption key.
                            type: string
                        required:
                        - kmsKeyName
                        type: object
                      destinationTable:
                        description: Describes the table where the query results should
                          be stored. This property must be set for large results that
                          exceed the maximum response size. For queries that produce
                          anonymous (cached) results, this field will be populated
                          by BigQuery.
                        properties:
                          datasetID:
                            description: The ID of the dataset containing this table.
                            type: string
                          projectID:
                            description: The ID of the project containing this table.
                            type: string
                          tableID:
                            description: The table. Can be specified '{{table_id}}'
                              if 'project_id' and 'dataset_id' are also set, or of
                              the form 'projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}'
                              if not.
                            type: string
                        required:
                        - tableID
                        type: object
                      flattenResults:
                        description: If true and query uses legacy SQL dialect, flattens
                          all nested and repeated fields in the query results. allowLargeResults
                          must be true if this is set to false. For standard SQL queries,
                          this flag is ignored and results are never flattened.
                        type: boolean
                      maximumBillingTier:
                        description: Limits the billing tier for this job. Queries
                          that have resource usage beyond this tier will fail (without
                          incurring a charge). If unspecified, this will be set to
                          your project default.
                        format: int64
                        type: integer
                      maximumBytesBilled:
                        description: Limits the bytes billed for this job. Queries
                          that will have bytes billed beyond this limit will fail
                          (without incurring a charge). If unspecified, this will
                          be set to your project default.
                        type: string
                      parameterMode:
                        description: Standard SQL only. Set to POSITIONAL to use positional
                          (?) query parameters or to NAMED to use named (@myparam)
                          query parameters in this query.
                        type: string
                      priority:
                        description: 'Specifies a priority for the query. Default
                          value: "INTERACTIVE" Possible values: ["INTERACTIVE", "BATCH"]'
                        type: string
                      query:
                        description: 'SQL query text to execute. The useLegacySql
                          field can be used to indicate whether the query uses legacy
                          SQL or standard SQL. *NOTE*: queries containing [DML language](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language)
                          (''DELETE'', ''UPDATE'', ''MERGE'', ''INSERT'') must specify
                          ''create_disposition = ""'' and ''write_disposition = ""''.'
                        type: string
                      schemaUpdateOptions:
                        description: 'Allows the schema of the destination table to
                          be updated as a side effect of the query job. Schema update
                          options are supported in two cases: when writeDisposition
                          is WRITE_APPEND; when writeDisposition is WRITE_TRUNCATE
                          and the destination table is a partition of a table, specified
                          by partition decorators. For normal tables, WRITE_TRUNCATE
                          will always overwrite the schema. One or more of the following
                          values are specified: ALLOW_FIELD_ADDITION: allow adding
                          a nullable field to the schema. ALLOW_FIELD_RELAXATION:
                          allow relaxing a required field in the original schema to
                          nullable.'
                        items:
                          type: string
                        type: array
                      scriptOptions:
                        description: Options controlling the execution of scripts.
                        properties:
                          keyResultStatement:
                            description: 'Determines which statement in the script
                              represents the "key result", used to populate the schema
                              and query results of the script job. Possible values:
                              ["LAST", "FIRST_SELECT"]'
                            type: string
                          statementByteBudget:
                            description: Limit on the number of bytes billed per statement.
                              Exceeding this budget results in an error.
                            type: string
                          statementTimeoutMs:
                            description: Timeout period for each statement in a script.
                            type: string
                        type: object
                      useLegacySQL:
                        description: Specifies whether to use BigQuery's legacy SQL
                          dialect for this query. The default value is true. If set
                          to false, the query will use BigQuery's standard SQL.
                        type: boolean
                      useQueryCache:
                        description: Whether to look for the result in the query cache.
                          The query cache is a best-effort cache that will be flushed
                          whenever tables in the query are modified. Moreover, the
                          query cache is only available when a query does not have
                          a destination table specified. The default value is true.
                        type: boolean
                      userDefinedFunctionResources:
                        description: Describes user-defined function resources used
                          in the query.
                        items:
                          properties:
                            inlineCode:
                              description: An inline resource that contains code for
                                a user-defined function (UDF). Providing a inline
                                code resource is equivalent to providing a URI for
                                a file containing the same code.
                              type: string
                            resourceURI:
                              description: A code resource to load from a Google Cloud
                                Storage URI (gs://bucket/path).
                              type: string
                          type: object
                        type: array
                      writeDisposition:
                        description: 'Specifies the action that occurs if the destination
                          table already exists. The following values are supported:
                          WRITE_TRUNCATE: If the table already exists, BigQuery overwrites
                          the table data and uses the schema from the query result.
                          WRITE_APPEND: If the table already exists, BigQuery appends
                          the data to the table. WRITE_EMPTY: If the table already
                          exists and contains data, a ''duplicate'' error is returned
                          in the job result. Each action is atomic and only occurs
                          if BigQuery is able to complete the job successfully. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion. Default value: "WRITE_EMPTY" Possible
                          values: ["WRITE_TRUNCATE", "WRITE_APPEND", "WRITE_EMPTY"]'
                        type: string
                    required:
                    - query
                    type: object
                  status:
                    description: The status of this job. Examine this value when polling
                      an asynchronous job to see if the job is complete.
                    items:
                      properties:
                        errorResult:
                          description: Final error result of the job. If present,
                            indicates that the job has completed and was unsuccessful.
                          items:
                            properties:
                              location:
                                description: Specifies where the error occurred, if
                                  present.
                                type: string
                              message:
                                description: A human-readable description of the error.
                                type: string
                              reason:
                                description: A short error code that summarizes the
                                  error.
                                type: string
                            type: object
                          type: array
                        errors:
                          description: The first errors encountered during the running
                            of the job. The final message includes the number of errors
                            that caused the process to stop. Errors here do not necessarily
                            mean that the job has not completed or was unsuccessful.
                          items:
                            properties:
                              location:
                                description: Specifies where the error occurred, if
                                  present.
                                type: string
                              message:
                                description: A human-readable description of the error.
                                type: string
                              reason:
                                description: A short error code that summarizes the
                                  error.
                                type: string
                            type: object
                          type: array
                        state:
                          description: Running state of the job. Valid states include
                            'PENDING', 'RUNNING', and 'DONE'.
                          type: string
                      type: object
                    type: array
                  timeouts:
                    properties:
                      create:
                        description: A Duration represents the elapsed time between
                          two instants as an int64 nanosecond count. The representation
                          limits the largest representable duration to approximately
                          290 years.
                        format: int64
                        type: integer
                      default:
                        description: A Duration represents the elapsed time between
                          two instants as an int64 nanosecond count. The representation
                          limits the largest representable duration to approximately
                          290 years.
                        format: int64
                        type: integer
                      delete:
                        description: A Duration represents the elapsed time between
                          two instants as an int64 nanosecond count. The representation
                          limits the largest representable duration to approximately
                          290 years.
                        format: int64
                        type: integer
                      read:
                        description: A Duration represents the elapsed time between
                          two instants as an int64 nanosecond count. The representation
                          limits the largest representable duration to approximately
                          290 years.
                        format: int64
                        type: integer
                      update:
                        description: A Duration represents the elapsed time between
                          two instants as an int64 nanosecond count. The representation
                          limits the largest representable duration to approximately
                          290 years.
                        format: int64
                        type: integer
                    type: object
                  userEmail:
                    description: Email address of the user who ran the job.
                    type: string
                required:
                - jobID
                type: object
              state:
                properties:
                  copy:
                    description: Copies a table.
                    properties:
                      createDisposition:
                        description: 'Specifies whether the job is allowed to create
                          new tables. The following values are supported: CREATE_IF_NEEDED:
                          If the table does not exist, BigQuery creates the table.
                          CREATE_NEVER: The table must already exist. If it does not,
                          a ''notFound'' error is returned in the job result. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion Default value: "CREATE_IF_NEEDED" Possible
                          values: ["CREATE_IF_NEEDED", "CREATE_NEVER"]'
                        type: string
                      destinationEncryptionConfiguration:
                        description: Custom encryption configuration (e.g., Cloud
                          KMS keys)
                        properties:
                          kmsKeyName:
                            description: Describes the Cloud KMS encryption key that
                              will be used to protect destination BigQuery table.
                              The BigQuery Service Account associated with your project
                              requires access to this encryption key.
                            type: string
                        required:
                        - kmsKeyName
                        type: object
                      destinationTable:
                        description: The destination table.
                        properties:
                          datasetID:
                            description: The ID of the dataset containing this table.
                            type: string
                          projectID:
                            description: The ID of the project containing this table.
                            type: string
                          tableID:
                            description: The table. Can be specified '{{table_id}}'
                              if 'project_id' and 'dataset_id' are also set, or of
                              the form 'projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}'
                              if not.
                            type: string
                        required:
                        - tableID
                        type: object
                      sourceTables:
                        description: Source tables to copy.
                        items:
                          properties:
                            datasetID:
                              description: The ID of the dataset containing this table.
                              type: string
                            projectID:
                              description: The ID of the project containing this table.
                              type: string
                            tableID:
                              description: The table. Can be specified '{{table_id}}'
                                if 'project_id' and 'dataset_id' are also set, or
                                of the form 'projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}'
                                if not.
                              type: string
                          required:
                          - tableID
                          type: object
                        type: array
                      writeDisposition:
                        description: 'Specifies the action that occurs if the destination
                          table already exists. The following values are supported:
                          WRITE_TRUNCATE: If the table already exists, BigQuery overwrites
                          the table data and uses the schema from the query result.
                          WRITE_APPEND: If the table already exists, BigQuery appends
                          the data to the table. WRITE_EMPTY: If the table already
                          exists and contains data, a ''duplicate'' error is returned
                          in the job result. Each action is atomic and only occurs
                          if BigQuery is able to complete the job successfully. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion. Default value: "WRITE_EMPTY" Possible
                          values: ["WRITE_TRUNCATE", "WRITE_APPEND", "WRITE_EMPTY"]'
                        type: string
                    required:
                    - sourceTables
                    type: object
                  extract:
                    description: Configures an extract job.
                    properties:
                      compression:
                        description: The compression type to use for exported files.
                          Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
                          The default value is NONE. DEFLATE and SNAPPY are only supported
                          for Avro.
                        type: string
                      destinationFormat:
                        description: The exported file format. Possible values include
                          CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL
                          for models. The default value for tables is CSV. Tables
                          with nested or repeated fields cannot be exported as CSV.
                          The default value for models is SAVED_MODEL.
                        type: string
                      destinationUris:
                        description: A list of fully-qualified Google Cloud Storage
                          URIs where the extracted table should be written.
                        items:
                          type: string
                        type: array
                      fieldDelimiter:
                        description: When extracting data in CSV format, this defines
                          the delimiter to use between fields in the exported data.
                          Default is ','
                        type: string
                      printHeader:
                        description: Whether to print out a header row in the results.
                          Default is true.
                        type: boolean
                      sourceModel:
                        description: A reference to the model being exported.
                        properties:
                          datasetID:
                            description: The ID of the dataset containing this model.
                            type: string
                          modelID:
                            description: The ID of the model.
                            type: string
                          projectID:
                            description: The ID of the project containing this model.
                            type: string
                        required:
                        - datasetID
                        - modelID
                        - projectID
                        type: object
                      sourceTable:
                        description: A reference to the table being exported.
                        properties:
                          datasetID:
                            description: The ID of the dataset containing this table.
                            type: string
                          projectID:
                            description: The ID of the project containing this table.
                            type: string
                          tableID:
                            description: The table. Can be specified '{{table_id}}'
                              if 'project_id' and 'dataset_id' are also set, or of
                              the form 'projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}'
                              if not.
                            type: string
                        required:
                        - tableID
                        type: object
                      useAvroLogicalTypes:
                        description: Whether to use logical types when extracting
                          to AVRO format.
                        type: boolean
                    required:
                    - destinationUris
                    type: object
                  id:
                    type: string
                  jobID:
                    description: The ID of the job. The ID must contain only letters
                      (a-z, A-Z), numbers (0-9), underscores (_), or dashes (-). The
                      maximum length is 1,024 characters.
                    type: string
                  jobTimeoutMs:
                    description: Job timeout in milliseconds. If this time limit is
                      exceeded, BigQuery may attempt to terminate the job.
                    type: string
                  jobType:
                    description: The type of the job.
                    type: string
                  labels:
                    additionalProperties:
                      type: string
                    description: The labels associated with this job. You can use
                      these to organize and group your jobs.
                    type: object
                  load:
                    description: Configures a load job.
                    properties:
                      allowJaggedRows:
                        description: Accept rows that are missing trailing optional
                          columns. The missing values are treated as nulls. If false,
                          records with missing trailing columns are treated as bad
                          records, and if there are too many bad records, an invalid
                          error is returned in the job result. The default value is
                          false. Only applicable to CSV, ignored for other formats.
                        type: boolean
                      allowQuotedNewlines:
                        description: Indicates if BigQuery should allow quoted data
                          sections that contain newline characters in a CSV file.
                          The default value is false.
                        type: boolean
                      autodetect:
                        description: Indicates if we should automatically infer the
                          options and schema for CSV and JSON sources.
                        type: boolean
                      createDisposition:
                        description: 'Specifies whether the job is allowed to create
                          new tables. The following values are supported: CREATE_IF_NEEDED:
                          If the table does not exist, BigQuery creates the table.
                          CREATE_NEVER: The table must already exist. If it does not,
                          a ''notFound'' error is returned in the job result. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion Default value: "CREATE_IF_NEEDED" Possible
                          values: ["CREATE_IF_NEEDED", "CREATE_NEVER"]'
                        type: string
                      destinationEncryptionConfiguration:
                        description: Custom encryption configuration (e.g., Cloud
                          KMS keys)
                        properties:
                          kmsKeyName:
                            description: Describes the Cloud KMS encryption key that
                              will be used to protect destination BigQuery table.
                              The BigQuery Service Account associated with your project
                              requires access to this encryption key.
                            type: string
                        required:
                        - kmsKeyName
                        type: object
                      destinationTable:
                        description: The destination table to load the data into.
                        properties:
                          datasetID:
                            description: The ID of the dataset containing this table.
                            type: string
                          projectID:
                            description: The ID of the project containing this table.
                            type: string
                          tableID:
                            description: The table. Can be specified '{{table_id}}'
                              if 'project_id' and 'dataset_id' are also set, or of
                              the form 'projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}'
                              if not.
                            type: string
                        required:
                        - tableID
                        type: object
                      encoding:
                        description: The character encoding of the data. The supported
                          values are UTF-8 or ISO-8859-1. The default value is UTF-8.
                          BigQuery decodes the data after the raw, binary data has
                          been split using the values of the quote and fieldDelimiter
                          properties.
                        type: string
                      fieldDelimiter:
                        description: The separator for fields in a CSV file. The separator
                          can be any ISO-8859-1 single-byte character. To use a character
                          in the range 128-255, you must encode the character as UTF8.
                          BigQuery converts the string to ISO-8859-1 encoding, and
                          then uses the first byte of the encoded string to split
                          the data in its raw, binary state. BigQuery also supports
                          the escape sequence "\t" to specify a tab separator. The
                          default value is a comma (',').
                        type: string
                      ignoreUnknownValues:
                        description: 'Indicates if BigQuery should allow extra values
                          that are not represented in the table schema. If true, the
                          extra values are ignored. If false, records with extra columns
                          are treated as bad records, and if there are too many bad
                          records, an invalid error is returned in the job result.
                          The default value is false. The sourceFormat property determines
                          what BigQuery treats as an extra value: CSV: Trailing columns
                          JSON: Named values that don''t match any column names'
                        type: boolean
                      maxBadRecords:
                        description: The maximum number of bad records that BigQuery
                          can ignore when running the job. If the number of bad records
                          exceeds this value, an invalid error is returned in the
                          job result. The default value is 0, which requires that
                          all records are valid.
                        format: int64
                        type: integer
                      nullMarker:
                        description: Specifies a string that represents a null value
                          in a CSV file. For example, if you specify "\\N", BigQuery
                          interprets "\\N" as a null value when loading a CSV file.
                          The default value is the empty string. If you set this property
                          to a custom value, BigQuery throws an error if an empty
                          string is present for all data types except for STRING and
                          BYTE. For STRING and BYTE columns, BigQuery interprets the
                          empty string as an empty value.
                        type: string
                      projectionFields:
                        description: If sourceFormat is set to "DATASTORE_BACKUP",
                          indicates which entity properties to load into BigQuery
                          from a Cloud Datastore backup. Property names are case sensitive
                          and must be top-level properties. If no properties are specified,
                          BigQuery loads all properties. If any named property isn't
                          found in the Cloud Datastore backup, an invalid error is
                          returned in the job result.
                        items:
                          type: string
                        type: array
                      quote:
                        description: The value that is used to quote data sections
                          in a CSV file. BigQuery converts the string to ISO-8859-1
                          encoding, and then uses the first byte of the encoded string
                          to split the data in its raw, binary state. The default
                          value is a double-quote ('"'). If your data does not contain
                          quoted sections, set the property value to an empty string.
                          If your data contains quoted newline characters, you must
                          also set the allowQuotedNewlines property to true.
                        type: string
                      schemaUpdateOptions:
                        description: 'Allows the schema of the destination table to
                          be updated as a side effect of the load job if a schema
                          is autodetected or supplied in the job configuration. Schema
                          update options are supported in two cases: when writeDisposition
                          is WRITE_APPEND; when writeDisposition is WRITE_TRUNCATE
                          and the destination table is a partition of a table, specified
                          by partition decorators. For normal tables, WRITE_TRUNCATE
                          will always overwrite the schema. One or more of the following
                          values are specified: ALLOW_FIELD_ADDITION: allow adding
                          a nullable field to the schema. ALLOW_FIELD_RELAXATION:
                          allow relaxing a required field in the original schema to
                          nullable.'
                        items:
                          type: string
                        type: array
                      skipLeadingRows:
                        description: 'The number of rows at the top of a CSV file
                          that BigQuery will skip when loading the data. The default
                          value is 0. This property is useful if you have header rows
                          in the file that should be skipped. When autodetect is on,
                          the behavior is the following: skipLeadingRows unspecified
                          - Autodetect tries to detect headers in the first row. If
                          they are not detected, the row is read as data. Otherwise
                          data is read starting from the second row. skipLeadingRows
                          is 0 - Instructs autodetect that there are no headers and
                          data should be read starting from the first row. skipLeadingRows
                          = N > 0 - Autodetect skips N-1 rows and tries to detect
                          headers in row N. If headers are not detected, row N is
                          just skipped. Otherwise row N is used to extract column
                          names for the detected schema.'
                        format: int64
                        type: integer
                      sourceFormat:
                        description: The format of the data files. For CSV files,
                          specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
                          For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON".
                          For Avro, specify "AVRO". For parquet, specify "PARQUET".
                          For orc, specify "ORC". [Beta] For Bigtable, specify "BIGTABLE".
                          The default value is CSV.
                        type: string
                      sourceUris:
                        description: 'The fully-qualified URIs that point to your
                          data in Google Cloud. For Google Cloud Storage URIs: Each
                          URI can contain one ''*'' wildcard character and it must
                          come after the ''bucket'' name. Size limits related to load
                          jobs apply to external data sources. For Google Cloud Bigtable
                          URIs: Exactly one URI can be specified and it has be a fully
                          specified and valid HTTPS URL for a Google Cloud Bigtable
                          table. For Google Cloud Datastore backups: Exactly one URI
                          can be specified. Also, the ''*'' wildcard character is
                          not allowed.'
                        items:
                          type: string
                        type: array
                      timePartitioning:
                        description: Time-based partitioning specification for the
                          destination table.
                        properties:
                          expirationMs:
                            description: Number of milliseconds for which to keep
                              the storage for a partition. A wrapper is used here
                              because 0 is an invalid value.
                            type: string
                          field:
                            description: If not set, the table is partitioned by pseudo
                              column '_PARTITIONTIME'; if set, the table is partitioned
                              by this field. The field must be a top-level TIMESTAMP
                              or DATE field. Its mode must be NULLABLE or REQUIRED.
                              A wrapper is used here because an empty string is an
                              invalid value.
                            type: string
                          type:
                            description: The only type supported is DAY, which will
                              generate one partition per day. Providing an empty string
                              used to cause an error, but in OnePlatform the field
                              will be treated as unset.
                            type: string
                        required:
                        - type
                        type: object
                      writeDisposition:
                        description: 'Specifies the action that occurs if the destination
                          table already exists. The following values are supported:
                          WRITE_TRUNCATE: If the table already exists, BigQuery overwrites
                          the table data and uses the schema from the query result.
                          WRITE_APPEND: If the table already exists, BigQuery appends
                          the data to the table. WRITE_EMPTY: If the table already
                          exists and contains data, a ''duplicate'' error is returned
                          in the job result. Each action is atomic and only occurs
                          if BigQuery is able to complete the job successfully. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion. Default value: "WRITE_EMPTY" Possible
                          values: ["WRITE_TRUNCATE", "WRITE_APPEND", "WRITE_EMPTY"]'
                        type: string
                    required:
                    - destinationTable
                    - sourceUris
                    type: object
                  location:
                    description: The geographic location of the job. The default value
                      is US.
                    type: string
                  project:
                    type: string
                  query:
                    description: Configures a query job.
                    properties:
                      allowLargeResults:
                        description: If true and query uses legacy SQL dialect, allows
                          the query to produce arbitrarily large result tables at
                          a slight cost in performance. Requires destinationTable
                          to be set. For standard SQL queries, this flag is ignored
                          and large results are always allowed. However, you must
                          still set destinationTable when result size exceeds the
                          allowed maximum response size.
                        type: boolean
                      createDisposition:
                        description: 'Specifies whether the job is allowed to create
                          new tables. The following values are supported: CREATE_IF_NEEDED:
                          If the table does not exist, BigQuery creates the table.
                          CREATE_NEVER: The table must already exist. If it does not,
                          a ''notFound'' error is returned in the job result. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion Default value: "CREATE_IF_NEEDED" Possible
                          values: ["CREATE_IF_NEEDED", "CREATE_NEVER"]'
                        type: string
                      defaultDataset:
                        description: Specifies the default dataset to use for unqualified
                          table names in the query. Note that this does not alter
                          behavior of unqualified dataset names.
                        properties:
                          datasetID:
                            description: The dataset. Can be specified '{{dataset_id}}'
                              if 'project_id' is also set, or of the form 'projects/{{project}}/datasets/{{dataset_id}}'
                              if not.
                            type: string
                          projectID:
                            description: The ID of the project containing this table.
                            type: string
                        required:
                        - datasetID
                        type: object
                      destinationEncryptionConfiguration:
                        description: Custom encryption configuration (e.g., Cloud
                          KMS keys)
                        properties:
                          kmsKeyName:
                            description: Describes the Cloud KMS encryption key that
                              will be used to protect destination BigQuery table.
                              The BigQuery Service Account associated with your project
                              requires access to this encryption key.
                            type: string
                        required:
                        - kmsKeyName
                        type: object
                      destinationTable:
                        description: Describes the table where the query results should
                          be stored. This property must be set for large results that
                          exceed the maximum response size. For queries that produce
                          anonymous (cached) results, this field will be populated
                          by BigQuery.
                        properties:
                          datasetID:
                            description: The ID of the dataset containing this table.
                            type: string
                          projectID:
                            description: The ID of the project containing this table.
                            type: string
                          tableID:
                            description: The table. Can be specified '{{table_id}}'
                              if 'project_id' and 'dataset_id' are also set, or of
                              the form 'projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}}'
                              if not.
                            type: string
                        required:
                        - tableID
                        type: object
                      flattenResults:
                        description: If true and query uses legacy SQL dialect, flattens
                          all nested and repeated fields in the query results. allowLargeResults
                          must be true if this is set to false. For standard SQL queries,
                          this flag is ignored and results are never flattened.
                        type: boolean
                      maximumBillingTier:
                        description: Limits the billing tier for this job. Queries
                          that have resource usage beyond this tier will fail (without
                          incurring a charge). If unspecified, this will be set to
                          your project default.
                        format: int64
                        type: integer
                      maximumBytesBilled:
                        description: Limits the bytes billed for this job. Queries
                          that will have bytes billed beyond this limit will fail
                          (without incurring a charge). If unspecified, this will
                          be set to your project default.
                        type: string
                      parameterMode:
                        description: Standard SQL only. Set to POSITIONAL to use positional
                          (?) query parameters or to NAMED to use named (@myparam)
                          query parameters in this query.
                        type: string
                      priority:
                        description: 'Specifies a priority for the query. Default
                          value: "INTERACTIVE" Possible values: ["INTERACTIVE", "BATCH"]'
                        type: string
                      query:
                        description: 'SQL query text to execute. The useLegacySql
                          field can be used to indicate whether the query uses legacy
                          SQL or standard SQL. *NOTE*: queries containing [DML language](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language)
                          (''DELETE'', ''UPDATE'', ''MERGE'', ''INSERT'') must specify
                          ''create_disposition = ""'' and ''write_disposition = ""''.'
                        type: string
                      schemaUpdateOptions:
                        description: 'Allows the schema of the destination table to
                          be updated as a side effect of the query job. Schema update
                          options are supported in two cases: when writeDisposition
                          is WRITE_APPEND; when writeDisposition is WRITE_TRUNCATE
                          and the destination table is a partition of a table, specified
                          by partition decorators. For normal tables, WRITE_TRUNCATE
                          will always overwrite the schema. One or more of the following
                          values are specified: ALLOW_FIELD_ADDITION: allow adding
                          a nullable field to the schema. ALLOW_FIELD_RELAXATION:
                          allow relaxing a required field in the original schema to
                          nullable.'
                        items:
                          type: string
                        type: array
                      scriptOptions:
                        description: Options controlling the execution of scripts.
                        properties:
                          keyResultStatement:
                            description: 'Determines which statement in the script
                              represents the "key result", used to populate the schema
                              and query results of the script job. Possible values:
                              ["LAST", "FIRST_SELECT"]'
                            type: string
                          statementByteBudget:
                            description: Limit on the number of bytes billed per statement.
                              Exceeding this budget results in an error.
                            type: string
                          statementTimeoutMs:
                            description: Timeout period for each statement in a script.
                            type: string
                        type: object
                      useLegacySQL:
                        description: Specifies whether to use BigQuery's legacy SQL
                          dialect for this query. The default value is true. If set
                          to false, the query will use BigQuery's standard SQL.
                        type: boolean
                      useQueryCache:
                        description: Whether to look for the result in the query cache.
                          The query cache is a best-effort cache that will be flushed
                          whenever tables in the query are modified. Moreover, the
                          query cache is only available when a query does not have
                          a destination table specified. The default value is true.
                        type: boolean
                      userDefinedFunctionResources:
                        description: Describes user-defined function resources used
                          in the query.
                        items:
                          properties:
                            inlineCode:
                              description: An inline resource that contains code for
                                a user-defined function (UDF). Providing a inline
                                code resource is equivalent to providing a URI for
                                a file containing the same code.
                              type: string
                            resourceURI:
                              description: A code resource to load from a Google Cloud
                                Storage URI (gs://bucket/path).
                              type: string
                          type: object
                        type: array
                      writeDisposition:
                        description: 'Specifies the action that occurs if the destination
                          table already exists. The following values are supported:
                          WRITE_TRUNCATE: If the table already exists, BigQuery overwrites
                          the table data and uses the schema from the query result.
                          WRITE_APPEND: If the table already exists, BigQuery appends
                          the data to the table. WRITE_EMPTY: If the table already
                          exists and contains data, a ''duplicate'' error is returned
                          in the job result. Each action is atomic and only occurs
                          if BigQuery is able to complete the job successfully. Creation,
                          truncation and append actions occur as one atomic update
                          upon job completion. Default value: "WRITE_EMPTY" Possible
                          values: ["WRITE_TRUNCATE", "WRITE_APPEND", "WRITE_EMPTY"]'
                        type: string
                    required:
                    - query
                    type: object
                  status:
                    description: The status of this job. Examine this value when polling
                      an asynchronous job to see if the job is complete.
                    items:
                      properties:
                        errorResult:
                          description: Final error result of the job. If present,
                            indicates that the job has completed and was unsuccessful.
                          items:
                            properties:
                              location:
                                description: Specifies where the error occurred, if
                                  present.
                                type: string
                              message:
                                description: A human-readable description of the error.
                                type: string
                              reason:
                                description: A short error code that summarizes the
                                  error.
                                type: string
                            type: object
                          type: array
                        errors:
                          description: The first errors encountered during the running
                            of the job. The final message includes the number of errors
                            that caused the process to stop. Errors here do not necessarily
                            mean that the job has not completed or was unsuccessful.
                          items:
                            properties:
                              location:
                                description: Specifies where the error occurred, if
                                  present.
                                type: string
                              message:
                                description: A human-readable description of the error.
                                type: string
                              reason:
                                description: A short error code that summarizes the
                                  error.
                                type: string
                            type: object
                          type: array
                        state:
                          description: Running state of the job. Valid states include
                            'PENDING', 'RUNNING', and 'DONE'.
                          type: string
                      type: object
                    type: array
                  timeouts:
                    properties:
                      create:
                        description: A Duration represents the elapsed time between
                          two instants as an int64 nanosecond count. The representation
                          limits the largest representable duration to approximately
                          290 years.
                        format: int64
                        type: integer
                      default:
                        description: A Duration represents the elapsed time between
                          two instants as an int64 nanosecond count. The representation
                          limits the largest representable duration to approximately
                          290 years.
                        format: int64
                        type: integer
                      delete:
                        description: A Duration represents the elapsed time between
                          two instants as an int64 nanosecond count. The representation
                          limits the largest representable duration to approximately
                          290 years.
                        format: int64
                        type: integer
                      read:
                        description: A Duration represents the elapsed time between
                          two instants as an int64 nanosecond count. The representation
                          limits the largest representable duration to approximately
                          290 years.
                        format: int64
                        type: integer
                      update:
                        description: A Duration represents the elapsed time between
                          two instants as an int64 nanosecond count. The representation
                          limits the largest representable duration to approximately
                          290 years.
                        format: int64
                        type: integer
                    type: object
                  userEmail:
                    description: Email address of the user who ran the job.
                    type: string
                required:
                - jobID
                type: object
              terminationPolicy:
                enum:
                - Delete
                - DoNotTerminate
                type: string
              updatePolicy:
                enum:
                - Destroy
                - DoNotDestroy
                type: string
            required:
            - providerRef
            - resource
            type: object
          status:
            properties:
              conditions:
                items:
                  properties:
                    lastTransitionTime:
                      description: Last time the condition transitioned from one status
                        to another. This should be when the underlying condition changed.  If
                        that is not known, then using the time when the API field
                        changed is acceptable.
                      format: date-time
                      type: string
                    message:
                      description: A human readable message indicating details about
                        the transition. This field may be empty.
                      type: string
                    observedGeneration:
                      description: If set, this represents the .metadata.generation
                        that the condition was set based upon. For instance, if .metadata.generation
                        is currently 12, but the .status.condition[x].observedGeneration
                        is 9, the condition is out of date with respect to the current
                        state of the instance.
                      format: int64
                      type: integer
                    reason:
                      description: The reason for the condition's last transition
                        in CamelCase. The specific API may choose whether or not this
                        field is considered a guaranteed API. This field may not be
                        empty.
                      type: string
                    status:
                      description: Status of the condition, one of True, False, Unknown.
                      type: string
                    type:
                      description: Type of condition in CamelCase or in foo.example.com/CamelCase.
                        Many .condition.type values are consistent across resources
                        like Available, but because arbitrary conditions can be useful
                        (see .node.status.conditions), the ability to deconflict is
                        important.
                      type: string
                  required:
                  - lastTransitionTime
                  - message
                  - reason
                  - status
                  - type
                  type: object
                type: array
              observedGeneration:
                description: Resource generation, which is updated on mutation by
                  the API Server.
                format: int64
                type: integer
              phase:
                description: Status defines the set of statuses a resource can have.
                type: string
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}
